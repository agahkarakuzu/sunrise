{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§  Brain imaging data structure\n",
    "![](../assets/bids_cover.png)\n",
    "\n",
    "```{note}\n",
    "[BIDS](https://bids-specification.readthedocs.io/) is a neuroimaging data standard.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import `pybids`\n",
    "\n",
    "This is a Python module to query BIDS-formatted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bids import BIDSLayout\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BIDS dataset is located at the Image folder\n",
    "data_path = '../Image'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a layout object \n",
    "\n",
    "This object will enable us to make queries to fetch file names using subject IDs, modalities or using BIDS entity values such as `chord1` as in `acq-chord1`.\n",
    "\n",
    "However, it does not come with readers. To that end, we will use `nibabel`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = BIDSLayout(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import `nibabel`\n",
    "\n",
    "This is a highly popular Python package for working with common neuroimaging file formats. You can see user documentation [here](https://nipy.org/nibabel/manual.html#manual)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch the nii image that belongs to the `chord1` acquisition\n",
    "\n",
    "Remember that we have 4 chords in Sunrise by Norah Jones. In the [first notebook](/1D-MUSIC.ipynb), we studied the sounds made by these different TRs in detail. Now it is time to see images generated while these notes were being played. \n",
    "\n",
    "As there is not a BIDS entity for varying TRs, I used freeform `acq` entity to distinguish these files. As suffix, I used `T1w`, just for the sake of creating an example dataset. \n",
    "\n",
    "```\n",
    "sub-ismrm_ses-sunrise_acq-chord1_T1w.nii.gz\n",
    "sub-ismrm_ses-sunrise_acq-chord2_T1w.nii.gz\n",
    "sub-ismrm_ses-sunrise_acq-chord3_T1w.nii.gz\n",
    "sub-ismrm_ses-sunrise_acq-chord4_T1w.nii.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The [0] in the end is because layout.get returns a list, and we need a single entry to load data using nibabel.\n",
    "'''\n",
    "\n",
    "# You can imagine why this layout is useful for larger datasets\n",
    "chord1 = layout.get(subject='ismrm', extension='nii.gz', suffix='T1w', return_type='file', acquisition='chord1')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "You will see that chord1 is type Nifti1Image. It contains some information about affine transformation, data shape, orientation etc.\n",
    "'''\n",
    "chord1 = nib.load(chord1)\n",
    "#chord1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "To extract the \"image part\" of the Nifti, we need to use get_fdata() method of nibabel.\n",
    "chord1_im is an ndarray.\n",
    "'''\n",
    "chord1_im = chord1.get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.imshow(chord1_im,color_continuous_scale='viridis')\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy matrix operations\n",
    "\n",
    "We already know how to manipulate arrays, but what about matrices? \n",
    "\n",
    "### Crop the matrix\n",
    "\n",
    "As you noticed image is closer to the right side of the display plane. Let's try cropping it first to center it. \n",
    "\n",
    "```\n",
    "chord1_im[row,col]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = px.imshow(chord1_im[10:90,20:100],color_continuous_scale='viridis')\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! Now, let's transform this matrix into a 1D array, perform this cropping on that array and reshape it back to a `90X90` image. \n",
    "\n",
    "![](assets/reshape.png)\n",
    "\n",
    "To convert a matrix into an array (vectorization), we can use `np.flatten()`, which by default flattens matrices in row-major (C-style) order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chord1_arry = chord1_im.flatten()\n",
    "chord1_arry.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization\n",
    "\n",
    "**Crop the vectorized image (1D) at the same locations we cropped the matrix (`chord1_im[10:90,20:100]`)**\n",
    "\n",
    "In row dimension, we omitted the first and last 10 elements from the matrix. To achieve this in an array, we need to drop 0th, 100th, 200th ... elements from the array to begin with the rows... Dropping those elements would shift the array by 10 elements, now what about the ones at the end of each row... ðŸ¤¯ But wait... Do we need to actully think about this? Of course not!\n",
    "\n",
    "That's when we can use [`np.meshgrid`](https://numpy.org/doc/stable/reference/generated/numpy.meshgrid.html) and [`numpy.ravel_multi_index`](https://numpy.org/doc/stable/reference/generated/numpy.ravel_multi_index.html) methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This should create a (2,80,80) matrix. The first matrix (xy_idx[0,:,:]) stores the row, and the second\n",
    "one stores the column indexes corresponding to the slicing by [10:90,20:100].\n",
    "\n",
    "IMPORTANT: \n",
    "Axis corrdinates vs matrix coordinates. \n",
    "\n",
    "We pass indexing='ij' argument for NumPy NOT TO transpose our matrix. Documentation reads:\n",
    "In the 2-D case with inputs of length M and N, the outputs are of shape (N, M) for â€˜xyâ€™ indexing \n",
    "and (M, N) for â€˜ijâ€™ indexing. \n",
    "'''\n",
    "xy_idx = np.array(np.meshgrid(np.arange(10,90),np.arange(20,100),indexing='ij'))\n",
    "\n",
    "# Here, we find \"linear (flattened) indexes of our 2D slice\"\n",
    "lin_idx = np.ravel_multi_index([xy_idx[0,:,:],xy_idx[1,:,:]], (100,100)).flatten()\n",
    "\n",
    "# Take elements indexed by lin_idx from the flattened image\n",
    "cropped = chord1_arry[lin_idx]\n",
    "\n",
    "# Reshape cropped image (80,80)\n",
    "cropped = cropped.reshape(80,80)\n",
    "\n",
    "# Display the image\n",
    "fig = px.imshow(cropped,color_continuous_scale='viridis')\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "To prove ourselves we did the right thing, let's subtract matrix-cropped and array-corrped \n",
    "images from each other and display them.\n",
    "\n",
    "TASK:\n",
    "Now try the same thing after dropping indexing='ij' argument from the np.meshgrid function. \n",
    "'''\n",
    "\n",
    "dif = chord1_im[10:90,20:100] - cropped\n",
    "px.imshow(dif,color_continuous_scale='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```{note}\n",
    "If you are wondering why I tortured you with linearized indexing as the first 2D example, I have a great blog post suggestion for you: [Look Ma, No For-Loops: Array Programming With NumPy](https://realpython.com/numpy-array-programming/#:~:text=When%20looping%20over%20an%20array,cleaner%20and%20faster%20Python%20code.)\n",
    "```\n",
    "\n",
    "When it comes to computation, there are really three concepts that lend NumPy its power:\n",
    "\n",
    "- Vectorization\n",
    "- Broadcasting\n",
    "- Indexing\n",
    "\n",
    "Now you know vectorization and how to map matrix indexes onto linearized indexes. To go from linear to vector indexes, you can use [`np.unravel_index`](https://numpy.org/doc/stable/reference/generated/numpy.unravel_index.html). \n",
    "\n",
    "We already know `broadcasting` and `indexing` from the first notebook. Looks like you know how to make the most out of NumPy now! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Rolling Phantom\n",
    "\n",
    "We will rotate our image by 10 degrees 36 times, and stack those images together to create an animation using Plotly :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage, misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's work with the cropped image\n",
    "chord1_im = chord1_im = chord1.get_fdata()[10:90,20:100]\n",
    "\n",
    "# This is how you can rotate an image by 30 degrees\n",
    "img_rot = ndimage.rotate(chord1_im, 30,reshape=False)\n",
    "\n",
    "fig = px.imshow(img_rot,color_continuous_scale='viridis')\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "for rot in np.arange(10,360,10):\n",
    "    cur = ndimage.rotate(chord1_im,rot,reshape=False)\n",
    "    frames.append(cur/cur.max())\n",
    "\n",
    "frames = np.array(frames)\n",
    "frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(frames,color_continuous_scale='viridis', animation_frame=0,template='plotly_dark')\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](assets/stack.png)\n",
    "\n",
    "In the example above, we initialized a list (`frames`) to create a collection of 2D image stacks in a Python list, then we used np.array() create a numpy object of it. This approach works fairly well. Depending on the dimension orders you want, you can use `np.reshape`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_reshaped = frames.reshape([80,35,80])\n",
    "frames_reshaped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy also provides some functions to stack array/matrix data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chord_im(acq_val):\n",
    "    chord = layout.get(subject='ismrm', extension='nii.gz', suffix='T1w', return_type='file', acquisition=acq_val)[0]\n",
    "    chord = nib.load(chord)\n",
    "    chord_im = chord.get_fdata()\n",
    "    return chord_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chord1 = get_chord_im('chord1')\n",
    "chord2 = get_chord_im('chord2')\n",
    "chord3 = get_chord_im('chord3')\n",
    "chord4 = get_chord_im('chord4')\n",
    "\n",
    "ch12_dim0 = np.stack((chord1, chord2))\n",
    "ch12_dim1 = np.stack((chord1, chord2), axis=1)\n",
    "ch12_dim2 = np.stack((chord1, chord2), axis=2)\n",
    "\n",
    "# You can define along which axis the images will be stacked\n",
    "print('Default np.stack axis: ', ch12_dim0.shape,\n",
    "      '\\nnp.stack axis=1: ', ch12_dim1.shape,\n",
    "      '\\nnp.stack axis=2: ', ch12_dim2.shape,\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack all chord images using np.dstack on the last axis\n",
    "\n",
    "stack = np.dstack((chord1, chord2, chord3, chord4))\n",
    "\n",
    "stack.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intensity vs TR\n",
    "\n",
    "```{note}\n",
    "We will define sphere's center manually (thanks to interactive plots) & plot how intensity changes across TRs.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "# Define sphere point locations\n",
    "# I listed these points by hovering over the image. Note that x and y locations \n",
    "# displayed on hover must be transposed while slicing the matrix. Again, axis coordinates\n",
    "# vs matrix coordinates. \n",
    "\n",
    "sphere_centers = {\"x\": [39,43,53,66,76,80,76,66,54,43], \"y\": [51,63,70,70,62,50,40,31,31,39],\"T1\":[\"T1: 1989ms\",\"T1: 1454ms\",\"T1: 984ms\",\"T1: 706ms\",\"T1: 496ms\",\"T1: 351ms\",\"T1: 247ms\",\"T1: 175ms\",\"T1: 125ms\",\"T1: 89ms\"]}\n",
    "\n",
    "fig = px.imshow(stack,color_continuous_scale='viridis', animation_frame=2,template='plotly_dark')\n",
    "fig.add_trace(go.Scatter(x=sphere_centers['x'],y=sphere_centers['y'],text=sphere_centers['T1'],mode='markers',marker=dict(color='white')))\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how we simply slice our stack to see signal change across 4 TRs in 10 spheres\n",
    "# Pay attention to the order of x and y\n",
    "signal_vs_tr = stack[sphere_centers['y'],sphere_centers['x'],:]\n",
    "signal_vs_tr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read metadata using BIDS layout & json to extract TRs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "TRs = list()\n",
    "for acq_val in ['chord1','chord2','chord3','chord4']:\n",
    "    f = open(layout.get(subject='ismrm', extension='json', suffix='T1w', return_type='file', acquisition=acq_val)[0],)\n",
    "    cur_meta = json.load(f)\n",
    "    f.close()\n",
    "    TRs.append(cur_meta['mri_RepetitionTime'])\n",
    "\n",
    "TRs = np.array(TRs)\n",
    "print('TRs are: ', TRs)\n",
    "\n",
    "# Sort them and obtain sorted idxs (ASCENDING ORDER)\n",
    "sort_index = np.argsort(TRs)\n",
    "sorted_TR = np.sort(TRs)\n",
    "print('Sort idxs are: ', sort_index)\n",
    "print('Sorted TRs are: ', sorted_TR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List comprehension is a powerful python feature. \n",
    "# Here, we use it to create a string for tagging pandas dataframe colums \n",
    "# with the respective TRs.\n",
    "trlist = [\"TR:\" + s for s in sorted_TR.astype(str)]\n",
    "\n",
    "# Using the sort index, we are re-arranging the order of intensity values.\n",
    "result=[signal_vs_tr[:,i] for i in sort_index]\n",
    "# Create a numpy object \n",
    "result = np.array(result)\n",
    "# Convert numpy matrix's transpose into a pandas dataframe\n",
    "df = pd.DataFrame(result.T, columns = trlist)\n",
    "df[\"Spheres\"] = ['S1','S2','S3','S4','S5','S6','S7','S8','S9','S10']\n",
    "df[\"T1ms\"]     = sphere_centers[\"T1\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(df,x=\"Spheres\",y=[\"TR:9.6\",\"TR:12.9\",\"TR:13.1\",\"TR:14.45\"],template='plotly_dark',hover_name=\"T1ms\")\n",
    "fig.update_layout(hovermode=\"x unified\")\n",
    "fig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
